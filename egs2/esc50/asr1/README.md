# ESC-50 Audio Classification Recipe

This recipe implements the audio classification task with a BEATs encoder and linear layer decoder model on the ESC-50 dataset, very close to what is described in [this paper](https://arxiv.org/abs/2212.09058).
More specifically, we provide the fine-tuning config and results for second last row in Table 1 (BEATS-iter3) from the paper.
We reuse part of the code from the [BEATs repository](https://github.com/microsoft/unilm/tree/master/beats) for this implementation.

# Training Details and Requirements
We perform 5-fold cross validation as is usually done on ESC-50 dataset.
This dataset has 2k samples with 400 samples in each fold.
Fine-tuning needs 1 GPU with 16 GB memory and runs for ~8 hours. 
Although the models converge much earlier ~2-3 hours but we re-use the hyper-parameters from the BEATs paper.
This might be improved in a later version to cut down on training time.


### Steps to run

1. Download ESC-50 dataset from [this repo](https://github.com/karolpiczak/ESC-50?tab=readme-ov-file#download) and set the path to its root directory in db.sh.
2. Download the BEATs checkpoint: [BEATs_iter3](https://github.com/microsoft/unilm/tree/master/beats) and change the `beats_ckpt_path` path in `conf/beats_classification.yaml`
3. Launch with `run_5fold.sh`


## Trained checkpoints
# [TODO]

Fine-tuned models: 
Fold-1: 
Fold-2: 
Fold-3: 
Fold-4: 
Fold-5: 


<!-- Generated by scripts/utils/show_asr_result.sh -->
# RESULTS

# [TODO]

<!-- Copied from the output produced by local/evaluation.py -->
## exp/asr_ft
```

```
